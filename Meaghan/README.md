# Meaghan Boykin
meaghan.b@protonmail.com

## LBNL WDE Internship Program SULI 2025

Human-in-the-loop refers to the incorporation of human knowledge into the training or operation of automated systems, such as machine learning models. Although it can improve the performance of automated systems, human-in-the-loop is not widely used in all fields, seemingly due to the lack of an ideal interface. This project develops a human-in-the-loop interface in VR, expanding on a pre-existing application developed at LBNL titled ASCRIBE-VR. The interface allows users to quickly review large amounts of image data and interactively validate image classifications generated by automated systems. It is designed for use with a currently unpublished machine learning script developed at LBNL that classifies images and clusters them in three dimensions based on their similarity. In the VR environment, users can physically grab and move images to sort and reclassify them, and the updated data can be exported to provide feedback to the system, potentially accelerating the process of image annotation for classification tasks.

<table border="0">
 <tr>
    <td><img src="https://github.com/dani-lbnl/introvision/blob/main/cameracomputervision.png" width="300">
    </td>
    <td>
     <p>
      Title: This Title is Valuable  <a href='https://docs.google.com/presentation/d/1dP4LKxXJEqRjHSPzQyw53Dt5rSOHMtr3rGaYTXCSiiA/edit?usp=sharing'>[slides]</a>
      <li> Author(s): <a href='http://bit.ly/idealdatascience'> Joe Mary Doe </a>
      <li> Research paper: <a href='sllslsls'>[PDF]</a> 
      </td>
 </tr>
</table>
