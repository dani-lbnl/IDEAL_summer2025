# Meaghan Boykin 
Computer Science Student at Sonoma State University, class of 2026.<br />
meaghan.b@protonmail.com<br />
https://www.linkedin.com/in/meaghan-boykin


## LBNL WDE Internship Program SULI 2025
<img src="https://github.com/dani-lbnl/IDEAL_summer2025/blob/main/Meaghan/Poster%20Results%20Section.png" width="430">
Human-in-the-loop refers to the incorporation of human knowledge into the training or operation of automated systems, such as machine learning models. Although it can improve the performance of automated systems, human-in-the-loop is not widely used in all fields, seemingly due to the lack of an ideal interface. This project develops a human-in-the-loop interface in VR, expanding on a pre-existing application developed at LBNL titled ASCRIBE-VR. The interface allows users to quickly review large amounts of image data and interactively validate image classifications generated by automated systems. It is designed for use with a currently unpublished machine learning script developed at LBNL that classifies images and clusters them in three dimensions based on their similarity. In the VR environment, users can physically grab and move images to sort and reclassify them, and the updated data can be exported to provide feedback to the system, potentially accelerating the process of image annotation for classification tasks.

### [A Short Demo Video](https://www.youtube.com/watch?v=LUYmMjWH7m4)
### [Poster Presented at the Summer 2025 WD&E Intern Poster Session](https://github.com/dani-lbnl/IDEAL_summer2025/blob/main/Meaghan/SULI%20Summer%202025%20Poster.pdf)

